from langchain_groq import ChatGroq
from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate
from langchain_community.tools.tavily_search import TavilySearchResults
web_search_tool = TavilySearchResults(k=1)
ChatGroq.model_rebuild()
llm = ChatGroq(
    model="meta-llama/llama-4-scout-17b-16e-instruct",
    # model="llama-3.1-8b-instant",
    temperature=0.0,
    max_retries=2,
)
class SplitDocuments(BaseModel):
  '''The document splitter for corrective retrieval augmented genertion'''
  split_doc_high_confidence: list[str] = Field(
      description="Sub parts of the document that are highly confident with the query"
  )
  split_doc_low_confidence: list[str] = Field(
      description="Sub parts of the document that are low confident with the query"
  )
class CallAgent:
  def __init__(self,
               agent_name:str,
               query,
               docs):
    self.agent=agent_name
    self.query=query
    self.docs=docs
  def question_rewriter(self):
    system = """You are a question rewriter that improves vague or general questions by using ambiguous documents to infer what specific information the user might be looking for.

    The document provided is an answer generated by llm and has a low confidence score, the web search is intented to get the exact factual info about that document.

    For example:-
    Original Question:
    What is taj mahal?

    Ambiguous Documents:
    The nearby marketplace is known for local food.

    Your Answer Should Be:
    Where is taj mahal? What is the nearby marketplace? What is the local food in this local marketplace?

    Make the rewritten question:
    - Specific and fact-seeking (e.g., ask for a number, date, reason, location, etc.)
    - Aligned with the clues found in the ambiguous document
    - Optimized for web search

    Do not repeat vague wording ‚Äî convert it into a pointed, specific query.
    Only output the improved question."""
    re_write_prompt =ChatPromptTemplate.from_messages([
        ("system", system),
        (
            "human",
            """Original Question:
    {question}

    Ambiguous Documents:
    {doc}

    Based on these, rewrite the question to be more specific and better suited for a web search.
    Only output the improved question.""",
        ),
    ])
    question_rewriter = re_write_prompt | llm
    return question_rewriter
  def confidence_splitter(self):
    structured_llm_splitter = llm.with_structured_output(SplitDocuments,)
    system = """
       You are a document splitter for corrective retrieval-augmented generation.

    Given a document and a question, split the document into:

    - HIGH CONFIDENCE parts: Sentences that provide **specific**, **qualitative**, **factual information** directly relevant to the question.
    - LOW CONFIDENCE parts: Sentences that are vague, general, off-topic, or that simply restate the question without providing new information.

    Speculative sentences, even if related, should be placed in low confidence if they contain uncertainty, conflicting opinions, or lack concrete facts.

    Only put a sentence in HIGH CONFIDENCE if it directly supports answering the question with facts, names, numbers, places, or detailed reasoning.

    Be strict. A sentence with just similar words or vague phrasing (e.g. "There are some places nearby") must go into LOW CONFIDENCE.

    Preserve sentence integrity; do not add or remove information.

    1. `split_doc_high_confidence`: Sentences that are highly relevant to answering the question directly.
    2. `split_doc_low_confidence`: Sentences that are only weakly related or irrelevant to the question.

    Instructions:
    - Words like many, most, like if not used with some exact data like number, location, reason etc signify low confidence
    - Documents not containing exact data are considered low confidence.
    - Use only the original content from the document.
    - Do NOT add new facts or modify meaning.
    - Ensure each item is a complete sentence.
    - Place every sentence from the document into one and only one of the two categories.
    - Return the result in the format expected by the `SplitDocuments` schema:
    - `split_doc_high_confidence`: List of strings
    - `split_doc_low_confidence`: List of strings

    For example:
    Question : How good is iit indore?
    Document : Many placement companies come to iit indore for placements
    Answer :
    split_doc_high_confidence=[] split_doc_low_confidence=['Many placement companies come to iit indore for placements']
    """
    grade_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system),
            ("human", '''
            A confident document is one which contains **exact qualitative** and **strictly factual** information only. Otherwise it is low confidence
            Retrieved document: \n\n {document} \n\n User question: {question}'''),
        ]
    )

    retrieval_splitter = grade_prompt | structured_llm_splitter
    return retrieval_splitter
  def __call__(self):
    if self.agent in 'SPLITTER':
        return self.confidence_splitter()
    elif self.agent in 'REWRITER':
        return self.question_rewriter()
  
class QueryBreaker:
    def __init__(self):
      self.system='''
      Given a complex user query, split it into a list of simple, procedural questions that break the task down step by step. Do not include explanations or the original query. Just output the subqueries as questions.
      Example Input:

      "I want to book a flight to Paris, reserve a hotel, and schedule a cab from the airport."

      Output:

      What flight options are available to Paris?

      Which hotels are available in Paris during my travel dates?

      How can I schedule a cab pickup from the airport in Paris?

      Instruction:
      -You may decide in how many parts you have to breack the query
      -If query is too simple just return the query
      -The resulting queries must be procedural and single step
      -Each query must seek some information
''' 
    def _prompt(self,question):
        prompt = ChatPromptTemplate.from_messages(
        [
            ("system", self.system),
            ("human", '''
            {question}'''),
        ]
    )
        return prompt
    def _get_chain(self,question):
       breaker_chain=self._prompt(question)|llm
       return breaker_chain
    def __call__(self, question : str):
       chain=self._get_chain(question)
       return chain.invoke({'question':question}).content
       
class Refiner:
    def __init__(self):
      self.system='''You are an AI Agent, you are a whole document. You have to Refine the document to make it suitable such that it can be given to another llm agent to produce answer. You only have to refine. Do not remove any kind of information. Give refined doc only and say nothing else.'''
    def __call__(self,document):
       prompt = ChatPromptTemplate.from_messages(
        [
            ("system", self.system),
            ("human", '''
            {question}'''),
        ]
    )
       chain = prompt|llm
       return chain.invoke({'question':document}).content
class FinalLayer:
    def __init__(self):
      self.system='''You are given a set of procedural subqueries and a block of context.

Your task is to answer the subqueries one by one, in order, using only the information provided in the context.

Then, synthesize the answers into a single, coherent final response.

The Final answer must never contain any words like 'Context does not provide enough information', in such a case simply information is not available in this regard

The final response must be:

Comprehensive: Cover all aspects asked in the subqueries

Accurate: Stick strictly to the context; do not make up information

Useful: Present information clearly and helpfully

You may organize the final response using headings and bullet points for clarity.
You are an expert assistant responding to a user.
You have access to a set of factual details (not visible to the user).

Given a set of procedural subqueries, answer them as naturally and helpfully as possible, using only the information provided.

Do not refer to the data as ‚Äúcontext,‚Äù ‚Äúinput,‚Äù or ‚Äúscraped.‚Äù

Do not say that something is ‚Äúmissing‚Äù from the data.

If certain specifics are unavailable, answer only what can be said confidently, and phrase it as a general insight.

The final response must be:

‚úÖ Helpful and natural

‚úÖ Accurate to the available information

‚úÖ Free from any mention of internal system details

You may suggest realistic next steps for the user (e.g., contacting faculty), but only if they match normal user-facing behavior.

üõë Never say: ‚ÄúThe context does not mention...‚Äù, ‚ÄúThe input says...‚Äù, or anything that reveals backend mechanics.
‚úÖ Only provide the final response, clearly structured, as if in a natural conversation.
Output only the final response, not the subqueries or intermediate steps.

**If you feel that information given through context is not enough just simply say Information Not Available for Given Query. Don't make-up answers yourself.
'''
    def __call__(self,queries,context):
      prompt = ChatPromptTemplate.from_messages(
        [
            ("system", self.system),
            ("human", '''
            The Queries are :-
             {queries}
            The context is :- 
             {context}
            '''),
        ]
      )
      chain = prompt|llm
      return chain.invoke({'queries':queries,'context':context}).content